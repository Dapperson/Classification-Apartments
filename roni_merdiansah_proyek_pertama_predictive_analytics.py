# -*- coding: utf-8 -*-
"""Roni Merdiansah_Proyek Pertama : Predictive Analytics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/148TCIy31AB3La7tFlldPe5vR2VTudwPa

https://www.kaggle.com/datasets/aleshagavrilov/parishousing

aleshagavrilov/parishousing

https://www.kaggle.com/datasets/moonnectar/car-auction-sale-data-ebay-sold-listings

moonnectar/car-auction-sale-data-ebay-sold-listings

## Mengunduh Data
"""

! pip install -q kaggle

from google.colab import files

files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

!kaggle datasets download -d aleshagavrilov/parishousing

!mkdir parishousing
!unzip parishousing.zip -d parishousing
!ls parishousing

"""## Mempersiapkan Data"""

#Importing the Libraries
import numpy as np
import pandas as pd
import datetime
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt, numpy as np
from sklearn import metrics
import warnings
import sys
if not sys.warnoptions:
    warnings.simplefilter("ignore")
np.random.seed(42)
from functools import reduce

pd.set_option('display.max_columns', None)

df = pd.read_csv('/content/parishousing/ParisHousing.csv')

df

df.info()

"""## Membersihkan Data

### Cek Nilai Null
"""

df.isnull().sum()

"""Tidak terdapat nilai null

### Menghapus Kolom yang Tidak Dibutuhkan
"""

droped_df = df.drop(['Unnamed: 0', 'cityCode'], axis=1)

"""### Format Ulang String"""

droped_df['numberOfRooms'] = droped_df['numberOfRooms'].str.replace('-', ' ')

droped_df[['numberOfRooms']]

pip install word2number

from word2number import w2n

droped_df['numberOfRooms'] = droped_df['numberOfRooms'].apply(w2n.word_to_num)

droped_df[['numberOfRooms']]

"""Sekarang kolom `numberOfRooms` sudah menjadi numerikal"""

clean_df = droped_df.copy()

"""## Exploratory Data Analysis"""

clean_df.info()

"""### Presentase Category"""

clean_df['category'].value_counts()

fig, ax = plt.subplots()
labels = ['Basic','Luxury']
churn = clean_df['category'].value_counts()
ax.pie(churn, labels=labels, autopct='%.0f%%')
plt.title('Percetage of Housing Category', fontsize=20)
plt.show()

"""### Variabel Numerik"""

clean_df.describe()

numerical_columns = ['squareMeters',
                     'numberOfRooms',
                     'floors',
                     'cityPartRange',
                     'numPrevOwners',
                     'basement',
                     'attic',
                     'garage',
                     'hasGuestRoom',
                     'price']

fig, ax = plt.subplots(5, 2, figsize=(15, 25))
clean_df[clean_df.category == 'Basic'][numerical_columns].hist(bins=20, alpha=0.8, ax=ax)
clean_df[clean_df.category == 'Luxury'][numerical_columns].hist(bins=20, alpha=0.8, ax=ax)
plt.show()

"""### Variabel Kategorik"""

categorical_columns = ['isNewBuilt', 'made', 'hasStormProtector', 'hasStorageRoom', 'category','PoolAndYard']

plt.figure(figsize = (15,20))
for i in range(0, len(categorical_columns)):
    plt.subplot(5, 2, i+1)
    ax = sns.countplot(x=clean_df[categorical_columns[i]], palette='winter', orient='h')
    ax.tick_params(axis='both', which='major', pad=10)
    plt.tight_layout()
    plt.xticks(rotation=90,fontsize=10)
    plt.yticks(fontsize=10)
    plt.ylabel(ylabel='Count',fontsize=15)
    plt.xlabel(xlabel=categorical_columns[i],fontsize=15)

"""## Feature Engineering

### Label Encode
"""

s = (clean_df.dtypes != 'int64')
object_cols = list(s[s].index)

object_cols

from sklearn.preprocessing import OneHotEncoder

object_cols.remove('price')
object_cols.remove('category')

categorical_data = clean_df[object_cols]

OHE=OneHotEncoder(categories='auto')

feature_arr = OHE.fit_transform(categorical_data).toarray()

ohe_labels = OHE.get_feature_names(object_cols)

features = pd.DataFrame(feature_arr,columns=ohe_labels)

features

LE = LabelEncoder()
clean_df['category'] = LE.fit_transform(clean_df['category'])

clean_df = clean_df.drop(object_cols, axis=1)
clean_df = pd.concat([clean_df, features], axis=1)

clean_df

"""### Feature Selection"""

X = clean_df.drop(['category', 'made'], axis=1)
y = clean_df['category']

"""## Pemodelan

### Split Data
"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("X_train dataset shape: ", X_train.shape)
print("y_train dataset shape: ", y_train.shape)
print("X_test dataset shape: ", X_test.shape)
print("y_test dataset shape: ", y_test.shape)

"""### Baseline Model"""

#Machine learning Model
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC, LinearSVC
from sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier
from sklearn.ensemble import ExtraTreesClassifier
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier

#Cross Validation -> Untuk menangani data yang tidak balance
from sklearn.model_selection import StratifiedKFold 
from sklearn.model_selection import RepeatedStratifiedKFold

#Evaluation
from sklearn import metrics
from sklearn.metrics import classification_report, roc_auc_score, roc_curve
from sklearn.metrics import make_scorer,accuracy_score,roc_auc_score,precision_score,recall_score,f1_score,log_loss
from sklearn.metrics import confusion_matrix

# Modelling Algorithms
# StratifiedKFold adalah Cross Validation (CV)

kf = StratifiedKFold(n_splits=2,shuffle=True,random_state=42)

## Collect all model in one list
all_model = [DecisionTreeClassifier,
             GaussianNB,
             SVC,
             RandomForestClassifier]

model_name = ['DecisionTreeClassifier',
              'GaussianNB',
              'SVC',
              'RandomForestClassifier']
## loop for all model

datatr = []
datasc = []
Recall =[]
Precision =[]
auc =[]

for idx, model_type in enumerate(all_model):
    num = 1
    AccTrain = []
    AccTest = []
    RecallTemp = []
    PrecisionTemp = []
    AucTemp = []
    nfold = 1
    for train_index,test_index in kf.split(X,y): 

        print("----------BEFORE------------")
        print("{} Acc Train: {}, {} of KFold {}".format(model_name[idx], AccTrain, nfold, kf.n_splits))
        print("{} Acc Test: {}, {} of KFold {}".format(model_name[idx], AccTest, nfold, kf.n_splits))
        print("{} Recall: {}, {} of KFold {}".format(model_name[idx], RecallTemp, nfold, kf.n_splits))
        print("{} Precission: {}, {} of KFold {}".format(model_name[idx], PrecisionTemp, nfold, kf.n_splits))
        print("{} AUC: {}, {} of KFold {}".format(model_name[idx], AucTemp, nfold, kf.n_splits))
        print("---------------------------")
        
        X_train, X_test = X.loc[train_index], X.loc[test_index]
        y_train, y_test = y.loc[train_index], y.loc[test_index]
        
        model = model_type()
        model.fit(X_train,y_train)
        y_pred=model.predict(X_test)
        
        AccTrain.append(model.score(X_train , y_train))
        AccTest.append(model.score(X_test , y_test))
        RecallTemp.append(recall_score(y_test,y_pred))
        PrecisionTemp.append(precision_score(y_test,y_pred))
        AucTemp.append(roc_auc_score(y_test, y_pred))
        
        print("----------AFTER------------")
        print("{} Acc Train: {}, {} of KFold {}".format(model_name[idx], AccTrain, nfold, kf.n_splits))
        print("{} Acc Test: {}, {} of KFold {}".format(model_name[idx], AccTest, nfold, kf.n_splits))
        print("{} Recall: {}, {} of KFold {}".format(model_name[idx], RecallTemp, nfold, kf.n_splits))
        print("{} Precission: {}, {} of KFold {}".format(model_name[idx], PrecisionTemp, nfold, kf.n_splits))
        print("{} AUC: {}, {} of KFold {}".format(model_name[idx], AucTemp, nfold, kf.n_splits))
        print("---------------------------")
        
        nfold += 1
    
    print("----------FINAL------------")
    print("{} Acc Train: {}".format(model_name[idx], np.mean(AccTrain)))
    print("{} Acc Test: {}".format(model_name[idx], np.mean(AccTest)))
    print("{} Recall: {}".format(model_name[idx], np.mean(RecallTemp)))
    print("{} Precission: {}".format(model_name[idx], np.mean(PrecisionTemp)))
    print("{} AUC: {}".format(model_name[idx], np.mean(AucTemp)))
    print("---------------------------")
    datatr.append(np.mean(AccTrain))
    datasc.append(np.mean(AccTest))
    Recall.append(np.mean(RecallTemp))
    Precision.append(np.mean(PrecisionTemp))
    auc.append(np.mean(AucTemp))

## compare model each other
data_hasil = pd.DataFrame()
data_hasil['model'] = model_name
data_hasil['Accuracy training'] = datatr
data_hasil['Accuracy test'] = datasc
data_hasil['Precision'] = Precision
data_hasil['Recall']= Recall
data_hasil['AUC'] = auc
data_hasil['gap'] = abs(data_hasil['Accuracy training'] - data_hasil['Accuracy test'])
data_hasil.sort_values(by='Accuracy test',ascending=False)

"""### DecisionTreeClassifier """

model = DecisionTreeClassifier()
model.fit(X_train,y_train)
y_pred=model.predict(X_test)

report = classification_report(y_true=y_test, y_pred=model.predict(X_test))
print(report)

confusion = confusion_matrix(y_true=y_test, y_pred=model.predict(X_test))
plt.figure(figsize=(8, 8))
sns.heatmap(confusion,
            xticklabels=["Positive", "Negative"],
            yticklabels=["Positive", "Negative"],
            annot=True, 
            annot_kws={"fontsize": "xx-large"},
            cmap='winter')

plt.show()

"""#### Feature Importance"""

import plotly.graph_objects as go

model.fit(X_train, y_train)
fig = go.Figure(go.Bar(
            x=model.feature_importances_,
            y=X_train.columns,
            orientation='h', marker_color='steelblue'))
fig.update_layout(title='<b>Estimating feature importance through the DecisionTreeClassifier model', title_x=0.5, 
                 xaxis_title="Feature importance", yaxis_title='Feature', barmode='stack', yaxis={'categoryorder':'total ascending'})

fig.show()

"""### RandomForestClassifier"""

random_forest = RandomForestClassifier()
random_forest.fit(X_train,y_train)
y_pred=random_forest.predict(X_test)

report_random_forest = classification_report(y_true=y_test, y_pred=random_forest.predict(X_test))
print(report_random_forest)

confusion_random_forest = confusion_matrix(y_true=y_test, y_pred=random_forest.predict(X_test))
plt.figure(figsize=(8, 8))
sns.heatmap(confusion_random_forest,
            xticklabels=["Positive", "Negative"],
            yticklabels=["Positive", "Negative"],
            annot=True, 
            annot_kws={"fontsize": "xx-large"},
            cmap='winter')

plt.show()

"""#### Feature Importance"""

random_forest.fit(X_train, y_train)
fig = go.Figure(go.Bar(
            x=random_forest.feature_importances_,
            y=X_train.columns,
            orientation='h', marker_color='steelblue'))
fig.update_layout(title='<b>Estimating feature importance through the RandomForestClassifier model', title_x=0.5, 
                 xaxis_title="Feature importance", yaxis_title='Feature', barmode='stack', yaxis={'categoryorder':'total ascending'})

fig.show()

"""## Evaluasi

### RandomForestClassifier

#### Hyperparameter Tuning
"""

#Grid Search
from sklearn.model_selection import GridSearchCV

rf_classifier = RandomForestClassifier()

param_RFC = { 
    'n_estimators': [200, 500],
    'max_features': ['auto', 'sqrt', 'log2'],
    'max_depth' : [5, 10, 20, 40, 80, 160, 320, 640],
    'criterion' :['gini', 'entropy']
}

cv = StratifiedKFold(n_splits=2)

rfc = GridSearchCV(estimator=rf_classifier, 
                 param_grid=param_RFC,
                 cv = cv, 
                 verbose=4)

rfc.fit(X_train, y_train)

print('Best Score: {}'.format(rfc.best_score_))
print('Best Hyperparameters: {}'.format(rfc.best_params_))

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("X_train dataset shape: ", X_train.shape)
print("y_train dataset shape: ", y_train.shape)
print("X_test dataset shape: ", X_test.shape)
print("y_test dataset shape: ", y_test.shape)

# Buat Model Pakai Best Param Dari GridSearchCV
modeltun = RandomForestClassifier(**rfc.best_params_)

# Melatih Model Pakai data train kita
model_fit = modeltun.fit(X_train,y_train)

# Cek Peforma model kita di data latih
y_pred_train=model_fit.predict(X_train)
print(classification_report(y_train,y_pred_train))

# Cek Peforma model kita di data test
y_pred_test=model_fit.predict(X_test)
print(classification_report(y_test,y_pred_test))

confusion = confusion_matrix(y_true=y_test, y_pred=model.predict(X_test))
plt.figure(figsize=(8, 8))
sns.heatmap(confusion,
            xticklabels=["Positive", "Negative"],
            yticklabels=["Positive", "Negative"],
            annot=True, 
            annot_kws={"fontsize": "xx-large"},
            cmap='winter')

plt.show()

""">Confusion Matrix dari Data Testing menunjukan bahwa nilai dari FP (False Positive) dan nilai dari FN (False Negative) seimbang (Symetric) yaitu `0 : 0`, sehingga metrik yang kami gunakan adalah `accuracy` dengan skor `1.0`

# END
"""